# -*- coding: utf-8 -*-
"""meditriage_app.py

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y8-UcDSjoDDdnv7XbRO1hONh4oV1Csl8
"""

import streamlit as st
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM
import torch

# Load model and tokenizer
@st.cache_resource
def load_model():
    model_name = 'google/flan-t5-large'
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)
    return tokenizer, model

tokenizer, model = load_model()

# Prompt builder
def build_prompt(symptom_text):
    return f"""
You are a hospital triage expert.
Classify the following symptoms into one of:
- non-urgent: mild and not likely to worsen
- urgent: moderately serious and may worsen
- emergency: life-threatening or critical condition
- futile: beyond medical help

Only respond with one label from the list above.
Symptoms: {symptom_text}
Answer:"""

# Streamlit UI
st.title("ðŸ©º MediTriage Chatbot")
user_input = st.text_area("Enter the symptoms here:")

if st.button("Classify"):
    if user_input:
        prompt = build_prompt(user_input)
        inputs = tokenizer(prompt, return_tensors="pt", truncation=True)
        outputs = model.generate(**inputs, max_length=50)
        response = tokenizer.decode(outputs[0], skip_special_tokens=True)
        st.success(f"ðŸ©º **Triage Level:** {response}")
    else:
        st.warning("Please enter symptoms to classify.")